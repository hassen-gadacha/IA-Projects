{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2fb9d5",
   "metadata": {},
   "source": [
    "# Q-Learning with FrozenLake                                                                  \n",
    "<br> \n",
    "In this Notebook, I'll implement an agent <b>that plays FrozenLake.</b>\n",
    "<img src=\"frozenlake.png\" alt=\"Frozen Lake\"/>\n",
    "\n",
    "The goal of this game is <b>to go from the starting state to the goal state</b> by walking only on frozen tiles and avoid holes .<br>However, the ice is slippery, <b>so you won't always move in the direction you intend (stochastic environment).</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48faf337",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b960237",
   "metadata": {},
   "source": [
    "To install the base Gymnasium library, use `pip install gymnasium`\n",
    "\n",
    "This does not include dependencies for all families of environments (there's a massive number, and some can be problematic to install on certain systems). You can install these dependencies for one family like `pip install gym[atari]` or use `pip install gym[all]` to install all dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a8de5",
   "metadata": {},
   "source": [
    "## Step 0: Import the dependencies üìö\n",
    "We use 4 libraries:\n",
    "- `Gymnasium` for our FrozenLake Environment\n",
    "- `Numpy` for handling arrays and our Qtable\n",
    "- `MatplotLib.pyplot` to plot graphs and visualize the leaning progress\n",
    "- `Pickle` for saving and loading Q-table to/from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cebcea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bed5a7",
   "metadata": {},
   "source": [
    "## Step 1: Create the environment üéÆ\n",
    "- Here I'll create the FrozenLake environment. \n",
    "- Gymnasium is the library <b> composed of many environments that I will use to train my agent.</b>\n",
    "- In our case I choose to use Frozen Lake."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8dc24a1a",
   "metadata": {},
   "source": [
    "  env = gym.make('FrozenLake-v1', map_name=\"8x8\", is_slippery=False, render_mode='human' if render else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35946b",
   "metadata": {},
   "source": [
    "## Step 2: Create the Q-table and initialize it üóÑÔ∏è\n",
    "- Now, I'll create my Q-table, to know how much rows (states) and columns (actions) we need, we need to calculate the action_size and the state_size\n",
    "- Gymnasium provides us a way to do that: `env.action_space.n` and `env.observation_space.n`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df638ebf",
   "metadata": {},
   "source": [
    "if(is_training):\n",
    "\tq = np.zeros((env.observation_space.n, env.action_space.n)) # init a 64 x 4 array\n",
    "  else:\n",
    "    f = open('frozen_lake8x8.pkl', 'rb')\n",
    "    q = pickle.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db9a87",
   "metadata": {},
   "source": [
    "## Step 3: Create the hyperparameters ‚öôÔ∏è\n",
    "- Here, I'll specify the hyperparameters"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65de51c5",
   "metadata": {},
   "source": [
    "    learning_rate_a = 0.9 # alpha or learning rate\n",
    "    discount_factor_g = 0.9 # gamma or discount rate. Near 0: more weight/reward placed on immediate state. Near 1: more on future state.\n",
    "    epsilon = 1         # 1 = 100% random actions\n",
    "    epsilon_decay_rate = 0.0001        # epsilon decay rate. 1/0.0001 = 10,000\n",
    "    rng = np.random.default_rng()   # random number generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f8430",
   "metadata": {},
   "source": [
    "## Step 4: The Q learning algorithm üß†\n",
    "- Now I implement the Q learning algorithm:\n",
    "<img src=\"qtable_algo.png\" alt=\"Q algo\"/>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dde93ed5",
   "metadata": {},
   "source": [
    " rewards_per_episode = np.zeros(episodes)\n",
    "\n",
    "    for i in range(episodes):\n",
    "        state = env.reset()[0]  # states: 0 to 63, 0=top left corner,63=bottom right corner\n",
    "        terminated = False      # True when fall in hole or reached goal\n",
    "        truncated = False       # True when actions > 200\n",
    "\n",
    "        while(not terminated and not truncated):\n",
    "            if is_training and rng.random() < epsilon:\n",
    "                action = env.action_space.sample() # actions: 0=left,1=down,2=right,3=up\n",
    "            else:\n",
    "                action = np.argmax(q[state,:])\n",
    "\n",
    "            new_state,reward,terminated,truncated,_ = env.step(action)\n",
    "\n",
    "            if is_training:\n",
    "                q[state,action] = q[state,action] + learning_rate_a * (\n",
    "                    reward + discount_factor_g * np.max(q[new_state,:]) - q[state,action]\n",
    "                )\n",
    "\n",
    "            state = new_state\n",
    "\n",
    "        epsilon = max(epsilon - epsilon_decay_rate, 0)\n",
    "\n",
    "        if(epsilon==0):\n",
    "            learning_rate_a = 0.0001\n",
    "\n",
    "        if reward == 1:\n",
    "            rewards_per_episode[i] = 1\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    sum_rewards = np.zeros(episodes)\n",
    "    for t in range(episodes):\n",
    "        sum_rewards[t] = np.sum(rewards_per_episode[max(0, t-100):(t+1)])\n",
    "    plt.plot(sum_rewards)\n",
    "    plt.savefig('frozen_lake8x8.png')\n",
    "\n",
    "    if is_training:\n",
    "        f = open(\"frozen_lake8x8.pkl\",\"wb\")\n",
    "        pickle.dump(q, f)\n",
    "        f.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #run(15000)\n",
    "\n",
    "    run(10, is_training=False, render=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3dfad5",
   "metadata": {},
   "source": [
    "## Visualization: Use my Q-table to play FrozenLake ! üëæ\n",
    "- After 10 000 episodes, our Q-table can be used as a \"cheatsheet\" to play FrozenLake\"\n",
    "- By running this cell you can see our agent playing FrozenLake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b054845b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run(episodes, is_training=True, render=False):\n",
    "\n",
    "    env = gym.make('FrozenLake-v1', map_name=\"8x8\", is_slippery=False, render_mode='human' if render else None)\n",
    "\n",
    "    if(is_training):\n",
    "        q = np.zeros((env.observation_space.n, env.action_space.n)) # init a 64 x 4 array\n",
    "    else:\n",
    "        f = open('frozen_lake8x8.pkl', 'rb')\n",
    "        q = pickle.load(f)\n",
    "        f.close()\n",
    "\n",
    "    learning_rate_a = 0.9 # alpha or learning rate\n",
    "    discount_factor_g = 0.9 # gamma or discount rate. Near 0: more weight/reward placed on immediate state. Near 1: more on future state.\n",
    "    epsilon = 1         # 1 = 100% random actions\n",
    "    epsilon_decay_rate = 0.0001        # epsilon decay rate. 1/0.0001 = 10,000\n",
    "    rng = np.random.default_rng()   # random number generator\n",
    "\n",
    "    rewards_per_episode = np.zeros(episodes)\n",
    "\n",
    "    for i in range(episodes):\n",
    "        state = env.reset()[0]  # states: 0 to 63, 0=top left corner,63=bottom right corner\n",
    "        terminated = False      # True when fall in hole or reached goal\n",
    "        truncated = False       # True when actions > 200\n",
    "\n",
    "        while(not terminated and not truncated):\n",
    "            if is_training and rng.random() < epsilon:\n",
    "                action = env.action_space.sample() # actions: 0=left,1=down,2=right,3=up\n",
    "            else:\n",
    "                action = np.argmax(q[state,:])\n",
    "\n",
    "            new_state,reward,terminated,truncated,_ = env.step(action)\n",
    "\n",
    "            if is_training:\n",
    "                q[state,action] = q[state,action] + learning_rate_a * (\n",
    "                    reward + discount_factor_g * np.max(q[new_state,:]) - q[state,action]\n",
    "                )\n",
    "\n",
    "            state = new_state\n",
    "\n",
    "        epsilon = max(epsilon - epsilon_decay_rate, 0)\n",
    "\n",
    "        if(epsilon==0):\n",
    "            learning_rate_a = 0.0001\n",
    "\n",
    "        if reward == 1:\n",
    "            rewards_per_episode[i] = 1\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    sum_rewards = np.zeros(episodes)\n",
    "    for t in range(episodes):\n",
    "        sum_rewards[t] = np.sum(rewards_per_episode[max(0, t-100):(t+1)])\n",
    "    plt.plot(sum_rewards)\n",
    "    plt.savefig('frozen_lake8x8.png')\n",
    "\n",
    "    if is_training:\n",
    "        f = open(\"frozen_lake8x8.pkl\",\"wb\")\n",
    "        pickle.dump(q, f)\n",
    "        f.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run(15000)\n",
    "\n",
    "    #run(1, is_training=False, render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
